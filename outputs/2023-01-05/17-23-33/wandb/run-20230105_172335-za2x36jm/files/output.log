Training day and night
{'datapath': '../../../data/processed', 'modelpath': '../../../models', 'reportspath': '../../../reports', 'batch_size': 16, 'lr': 0.001, 'n_epochs': 1, 'seed': 123}
Error executing job with overrides: []
Traceback (most recent call last):
  File "/Users/danielsvendsen/gitrepos/DanielsCookieCutterPlayground/src/models/train_model_wandb.py", line 92, in train
    log_image_table(images, top_class, labels, nn.Softmax(log_ps))
  File "/Users/danielsvendsen/gitrepos/DanielsCookieCutterPlayground/src/models/train_model_wandb.py", line 75, in log_image_table
    for img, pred, targ, prob in zip(images.to("cpu"), predicted.to("cpu"), labels.to("cpu"), probs.to("cpu")):
TypeError: 'Softmax' object is not iterable
Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
Epoch: [1/1], Loss: 0.2420
Softmax(
  dim=tensor([[ -1.0693,  -2.0643,   0.5659,   1.3721,  -6.5932,  -6.1540, -11.9984,
            10.3221,  -2.8154,   1.6502],
          [ -3.1122,  -2.2286,  -3.7147,  -8.1804,   9.5036,  -2.8576,  -2.5264,
            -3.5869,  -0.2780,   3.7816],
          [ -2.7961,  -2.5862,  -3.0155,  -9.1321,   9.1680,  -2.9175,   0.5516,
            -2.4317,  -1.8976,   2.2294],
          [  0.0359,  -0.3664,   2.0669,   1.4440,  -2.7591,  -0.6891,  -3.1803,
            -1.6300,   9.3345,  -1.5269],
          [  0.5505,  -4.3301,  -2.0350,  -7.4390,   0.0504,  -2.0565,   8.6676,
            -7.5549,  -3.4684,  -3.8598],
          [ -1.6190,  -6.5856,  -4.2575,  -4.2518,   4.7562,  -2.3590,  -6.3442,
            -1.1511,  -0.1417,   9.1965],
          [ 13.8825, -11.0110,  -5.3422, -11.9533,  -4.6319,  -2.4425,   2.9810,
            -5.4580,  -2.3639,  -5.6016],
          [ -5.0888,   9.1321,  -1.5236,  -7.0688,  -1.2790,  -6.2678,  -4.4807,
            -2.0576,  -6.1340,  -0.1287],
          [  1.6518,   1.8067,  13.4990,   4.1404,  -5.7690, -10.2166,  -6.0478,
             0.6441,   0.9393,  -4.0447],
          [ -1.5805,  -6.9077,  -3.6842,  -3.7304,   2.6353,  -3.9907,  -8.5135,
             1.4202,  -0.6031,   9.7514],
          [  0.4509,  -0.4651,   1.2196,  -1.6829,   0.2279,  -1.9561,  -2.2069,
            -6.3453,   9.6983,  -0.8252],
          [  1.4863,  -5.8283,  -0.1965,   0.6939,  -0.6162,  -0.2783,  -2.8916,
            -2.2284,   5.4473,   1.3147],
          [ -1.5851,  -0.8927,   1.5693,  10.8283,  -3.6405,  -0.8448,  -8.7191,
             1.3722,   1.0732,   1.8840],
          [ 12.6254,  -8.2032,  -0.1553,  -8.6989,  -0.6439,  -7.3325,  -0.6346,
            -4.1972,  -1.2933,  -3.7775],
          [ -2.3427,  -0.8912,   0.8346,  -0.7451,  -2.2915,   1.9565,  -1.7208,
            -1.8231,   5.9211,   0.8016],
          [ -2.1343,  -1.6766,   4.9167,   0.5768,  -0.3324,  -1.7231,  -3.4907,
            -0.5003,   2.8282,   2.0142]])
)